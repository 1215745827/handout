# 第六章 | 推荐流程详解(下)

## 前言

**C：** 本章节我们需要了解下源数据，掌握以下云音乐推荐系统的整体推荐流程，最后再把推荐系统的工程搭建好。

![image-20200606140213887](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\2_项目核心算法讲解(上).assets\image-20200606140213887.png)

![image-20200606172917002](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200606172917002.png)

## 1. 认识源数据

源数据分为四个部分：

- 保存在MySQL数据库中的有：

  - 歌曲信息表（歌曲数据和歌单数据来源于购买版权、免费歌曲、用户自定义上传。）

    ![image-20200606174055393](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200606174055393.png)

  - 歌单信息表（歌单推荐功能需要，暂时不重要）

    ![image-20200606174104213](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200606174104213.png)

  - 用户信息表（通过用户注册，自主填写或主动埋点采集等方式获取）

    ![image-20200606174255637](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200606174255637.png)

- 保存为日志文本数据的有：

  - 用户行为日志数据集（通过在app端埋点的方式，进行行为数据采集并解析得到）

    ![image-20200606175049806](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200606175049806.png)

## 2. 回顾云音乐推荐系统推荐流程

推荐流程按照用户种类划分， 执行不同的推荐策略， 整体的推荐流程可以总结如下：

1. 对于冷启动用户的推荐策略（没有用户行为数据）：

   采用全局热播和用户分群召回生成召回集， 并合并去重得到最终召回集， 最终随机在召回集中取出 10 首歌作为最终推荐的结果。

2. 对于普通用户的推荐策略：
   
   采用全局热播 + 分群热播 + ALS召回生成召回集，并合并去重得到最终召回集，使用用户行为数据训练 LR 模型， 使用 LR 模型预测召回集中歌曲的得分，最终得到排序结果，取 Top10 为每个用户进行最终的推荐 。

## 3. 搭建云音乐推荐系统

### 3.1 云音乐推荐系统实现流程

- 数据收集（数据将提供）
- 数据预处理
  - 将数据处理成ALS、LR等算法所需格式
- 推荐系统召回阶段实现
  - 热播召回、分群召回、ALS召回
- 推荐系统排序阶段实现
  - LR排序
- 推荐最终推荐结果
  - 合并召回集，使用LR进行排序取Top10进行推荐

以上的步骤为云音乐大数据推荐系统所进行的代码实现。  

### 3.2 数据预处理实现(了解)

#### 3.2.1 ALS算法数据预处理  

`ALS` 需要的数据格式为<userid、 itemid、 score>， 它实际是稀疏的 userid-itemid矩阵的笛卡尔积形式。 score 就是该用户对该首歌曲的“偏好” 得分， 这个得分是通过加权的方式得到的， 加权的细则为用户对歌曲产生了行为， 如果产生的行为是播放， 则累计 1 分， 下载 2 分、 分享 3 分、 收藏 4 分。 播放行为可以发生多次， 则多次加分。 真实项目中播放行为的加分上限为 10 分， 咱们项目中未做此限制。 

通过分析行为数据， 为所有用户对歌曲产生的行为进行聚合， 得到<userid、itemid、 score>元组， 之后再对元组进行归一化。 归一化是一种简化计算的方式，即将有量纲的表达式， 经过变换， 化为无量纲的表达式， 成为标量。 

在多种计算中都经常用到这种方法。 归一化的好处是将 score 分值控制在 0~1 之间， 更方便进行计算， 并且通过归一化之后的数据， 不会改变最终的计算结果， 并且可以提高计算效率。 最终返回<userid、 itemid、 score>为特征的 dataframe， 并进行保存， 以便后续 ALS 算法使用。  

![image-20200607144938499](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607144938499.png)

![image-20200607144957400](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607144957400.png)

ALS 预处理代码详见项目代码:
.\Rcm\src\main\scala\com\kgc\process\ALSProcessing.scala  

#### 3.2.2 LR 算法数据预处理  

LR 排序算法之前提过， 尽可能用到所有的特征数据， 在本项目中， LR 的特征数据使用到 userid、 itemid、 duration、 age、 gender、 active， 可以通过聚合用户信息表和用户行为表进行获取。 标签数据的确定是通过用户行为数据中listenTime 决定的。 当用户对一首歌听歌时间大于 60 秒时， 可以默认判断为该用户喜欢这首歌，所以标签为 1。 

在数据预处理时需要将 listenTime 转换为 status标签， status 为枚举值 1,0。 1 表示喜欢， 0 表示不喜欢。 最终将所有数据处理成<label,features> 的 元 组 ， 其 中 label 为 status 的 值 ， features 为 特 征 向 量Vector<userid、 itemid、 duration、 age、 gender、 active>。 将处理好的数据进行保存， 以便后续 LR 算法使用。

![image-20200607145018732](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607145018732.png)

LR 预处理代码详见：.\Rcm\src\main\scala\com\kgc\process\LRProcessing.scala

步骤如下：

1. 通过用户行为数据， 分为用户收藏歌单信息和用户歌曲行为信息。 选出用户特征属性字段和用户听歌信息中听歌时长（user_id， item_id， listenTime， gender，age， active）。  

2. 将 user_id 关联形成（label/status， Vector）；
3. Label/status : 取决于听歌完整时长,听歌时间大于 60s 认为是一次正反馈Label/status 为 1； 听歌时间小于 60s 认为是一次负反馈 Label/status 为 1。
4. Vector : 并将用户信息拼接组成向量（user_id， item_id， gender， age， active）。  

#### 3.2.3 FPG数据预处理(略)

1. 通过用户行为数据， 分为用户收藏歌单信息和用户歌曲行为信息。 以用户聚合， 选出用户收藏歌单信息和用户得分最高的 top20 首歌曲（如 2.2.4）。

2. 以 user_id 作为关联条件做聚合生成 user_id， song_id， song_list_id 数据集。将 song_id 和 song_list_id 打上对应 tag。

   目的： 是为了在最终生成的关联规则中找到 song_id=>song_list_id 的关联关系， 不打 tag 则区分不出那个 ID 是歌曲 id， 哪个 id 是歌单 id。
   
3. 将带了 tag 的歌曲歌单 id 放入一个 set 中， 作为一条训练数据（类似啤酒尿布官方案例中的购物单）。  

### 3.3 推荐系统召回实现

#### 3.3.1 热门歌曲召回

对所有用户行为数据， 筛选出播出最多次的歌曲。 筛选的方式使用聚合记数的方式， 得到播出最多次数的歌曲后， 对其进行排序。 将播出最多的 30 首歌进行保存， 数据整合成<itemid， rank>的格式。  

全局热播召回代码详情：
.\Rcm\src\main\scala\com\kgc\recall\GlobalRecall.scala  

数据流向图：  

![image-20200607145252101](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607145252101.png)

适用用户群： 冷启动&新用户
使用背景：

1. 通过用户播放行为获取 song_id 和 count（对歌曲播放次数统计）， 对此歌曲进行排序， 获得 song_id， rank。
2. 取出播放次数最高的 30 首歌作为全剧热播歌曲， 主要针对冷启动用户和新用户。  

![image-20200607145201673](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607145201673.png)

#### 3.3.2 用户分群召回

用户分群召回对歌曲召回的方式实际与热门召回相同， 只是在用户类型上做了分群。 就比如用户（性别女， 年龄段： 18~25， 活跃用户） 大都喜欢听《野狼disco》， 而用户（性别女， 年龄段 50 以上， 活跃用户） 大都喜欢听《最炫民族风》。

通过特征<gender、 age、 active>进行分群， 可以分为 3*6*3=48 个群组。 对这 48个群组分别计算最热歌曲排行。 最终整合数据<group,itemid,rank>， 每个群组选取 top30， 将数据保存。

用户分群召回代码详情：
.\Rcm\src\main\scala\com\kgc\recall\GroupRecall.scala

数据流向图：  

![image-20200607150415088](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607150415088.png)

使用背景：

根基用户行为特征表选出 user_id 和 song_id； 通过用户个人信息表选出用户分组特征（gender， age， active） 通过三者组合形成用户 group_id。

以 user_id 进行关联的到 user_id， user_group， user_group.

对 user_group 进行聚合 count 得到user_group， song_id， count； 并对 count值进行排序的到 user_id， song_id， rank。

取出每个 user_group 中排名前 30 的歌曲作为此分群热播歌曲， 对有用户画像却没有播放行为的新用户按照对应分群热播歌曲进行推荐。  

![image-20200607145354017](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607145354017.png)

#### 3.3.3 ALS召回

ALS 召回需要加载 ALS 预处理过后的数据， 这些数据是稀疏的 userid-itemid矩阵的笛卡尔积形式， ALS 通过这部分数据作为训练集， 训练得到 ALS 模型后，可以对 userid-itemid 矩阵进行“填充”， 填充完之后就得到了 userid-itemid 的稠密矩阵笛卡尔积的形式， 最终得到数据<userid,itemid,score>， 根据 score， 为每个 userid 选取 top30 个 itemid， 得到最终的 ALS 召回集。  

数据流向图：  

![image-20200607150617707](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607150617707.png)

算法简介：ALS 中文名作交替最小二乘法， 在机器学习中， ALS 特指使用最小二乘法求解的一个协同过滤算法， 是协同过滤中的一种。
使用背景：

1. 将 上 述 数 据 作 为 训 练 数 据 送 至 ALS 模 型 的 训 练 数 据（user_index,item_index,score） 得到 ALS 模型。
2. 通过 ALS 模型预测用户对物品的打分， 并取出得分排名靠前的物品作为此用户推荐集。（API 中有可以通过用户预测推荐物品， 亦有通过物品推荐适合适合用户， 具体可参考 SparkMlib 中 ALSmodel 中 API）
3. 数据量较大的时候需要中间落盘， 需要打断 spark 的 lineage。  

![image-20200607150527556](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607150527556.png)

### 3.4 推荐系统排序实现

LR 排序：LR 排序需要加载 LR 预处理过后的数据， 进行 LR 模型训练， 将训练好的 LR模型进行保存， 此时是将整个模型进行保存， 而非保存数据。

LR 排序代码详情：
.\Rcm\src\main\scala\com\kgc\rank\LogisticRegression.scala

相应流程：  

![image-20200607150840021](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607150840021.png)

算法简介： 逻辑回归（Logistic Regression） 是用于处理因变量为分类变量的回归问题， 常见的是二分类或二项分布问题， 也可以处理多分类问题， 它实际上是属于一种分类方法。

使用背景：  

注意： 需要全量数据作为训练数据将上述数据作为训练数据送至 LR 模型的训练数据得到 LR 模型。通过 LR 模型预测得到（vector，probability），通过取出 vecto（r user_id, item_id,oper_id, age, gender, active） 中user_id 和 item_id， 找到用户喜欢这首歌的probability（向量（前者代表不喜欢（status/lable 为 0） 的可能性， 后者代表喜欢（status/lable 为 1） 的可能性））， 取出喜欢的 probability 作为 score。  

![image-20200607150712838](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607150712838.png)

![image-20200607151019851](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607151019851.png)

### 3.5 搭建项目工程

1. 创建Maven项目

   ![image-20200607151750831](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607151750831.png)

2. 添加相应依赖

   ```xml
   <inceptionYear>2008</inceptionYear>
   <properties>
       <scala.version>2.11.11</scala.version>
       <spark.version>2.1.0</spark.version>
   </properties>
   
   <repositories>
       <repository>
           <id>scala-tools.org</id>
           <name>Scala-Tools Maven2 Repository</name>
           <url>http://scala-tools.org/repo-releases</url>
       </repository>
   </repositories>
   
   <pluginRepositories>
       <pluginRepository>
           <id>scala-tools.org</id>
           <name>Scala-Tools Maven2 Repository</name>
           <url>http://scala-tools.org/repo-releases</url>
       </pluginRepository>
   </pluginRepositories>
   
   <dependencies>
       <dependency>
           <groupId>org.scala-lang</groupId>
           <artifactId>scala-library</artifactId>
           <version>${scala.version}</version>
       </dependency>
       <dependency>
           <groupId>junit</groupId>
           <artifactId>junit</artifactId>
           <version>4.8.2</version>
           <scope>test</scope>
       </dependency>
       <dependency>
           <groupId>org.specs</groupId>
           <artifactId>specs</artifactId>
           <version>1.2.5</version>
           <scope>test</scope>
       </dependency>
       <!--<dependency>-->
       <!--<groupId>com.redislabs</groupId>-->
       <!--<artifactId>spark-redis</artifactId>-->
       <!--<version>2.3.1-RC1</version>-->
       <!--</dependency>-->
       <dependency>
           <groupId>com.redislabs</groupId>
           <artifactId>spark-redis</artifactId>
           <version>2.3.1-RC1</version>
       </dependency>
   
       <dependency>
           <groupId>org.apache.spark</groupId>
           <artifactId>spark-core_2.11</artifactId>
           <version>${spark.version}</version>
       </dependency>
       <dependency>
           <groupId>org.apache.spark</groupId>
           <artifactId>spark-sql_2.11</artifactId>
           <version>${spark.version}</version>
       </dependency>
       <dependency>
           <groupId>org.apache.spark</groupId>
           <artifactId>spark-hive_2.11</artifactId>
           <version>${spark.version}</version>
       </dependency>
       <dependency>
           <groupId>org.apache.spark</groupId>
           <artifactId>spark-mllib_2.11</artifactId>
           <version>${spark.version}</version>
       </dependency>
   
       <dependency>
           <groupId>log4j</groupId>
           <artifactId>log4j</artifactId>
           <version>1.2.17</version>
       </dependency>
   </dependencies>
   
   <build>
       <sourceDirectory>src/main/scala</sourceDirectory>
       <testSourceDirectory>src/test/scala</testSourceDirectory>
       <plugins>
           <plugin>
               <groupId>org.scala-tools</groupId>
               <artifactId>maven-scala-plugin</artifactId>
               <executions>
                   <execution>
                       <goals>
                           <goal>compile</goal>
                           <goal>testCompile</goal>
                       </goals>
                   </execution>
               </executions>
               <configuration>
                   <scalaVersion>${scala.version}</scalaVersion>
                   <args>
                       <arg>-target:jvm-1.5</arg>
                   </args>
               </configuration>
           </plugin>
           <plugin>
               <artifactId>maven-assembly-plugin</artifactId>
               <configuration>
                   <descriptorRefs>
                       <descriptorRef>jar-with-dependencies</descriptorRef>
                   </descriptorRefs>
               </configuration>
           </plugin>
           <plugin>
               <groupId>org.apache.maven.plugins</groupId>
               <artifactId>maven-eclipse-plugin</artifactId>
               <configuration>
                   <downloadSources>true</downloadSources>
                   <buildcommands>
                       <buildcommand>ch.epfl.lamp.sdt.core.scalabuilder</buildcommand>
                   </buildcommands>
                   <additionalProjectnatures>
                       <projectnature>ch.epfl.lamp.sdt.core.scalanature</projectnature>
                   </additionalProjectnatures>
                   <classpathContainers>
                       <classpathContainer>org.eclipse.jdt.launching.JRE_CONTAINER</classpathContainer>
                       <classpathContainer>ch.epfl.lamp.sdt.launching.SCALA_CONTAINER</classpathContainer>
                   </classpathContainers>
               </configuration>
           </plugin>
       </plugins>
   </build>
   <reporting>
       <plugins>
           <plugin>
               <groupId>org.scala-tools</groupId>
               <artifactId>maven-scala-plugin</artifactId>
               <configuration>
                   <scalaVersion>${scala.version}</scalaVersion>
               </configuration>
           </plugin>
       </plugins>
   </reporting>
   ```

3. 创建各模块

   ![image-20200607152201944](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607152201944.png)

   双击即可快速创建成功。

   ![image-20200607152243417](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607152243417.png)

   1. 数据预处理(preprocess)
   2. 召回实现(recall)
   3. 排序算法模型(rank)
   4. 排序实现(recommandation)
   5. Redis集成(integrate)

   ![image-20200607154256272](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607154256272.png)

创建每个模块所需要的类

![image-20200607155128429](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607155128429.png)

![image-20200607155212549](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607155212549.png)

![image-20200607155645847](H:\CHARLES7C_TEACH\查老师的讲义\Charles7cHandouts\docs\bigdata\4_推荐流程详解(上).assets\image-20200607155645847.png)

## 后记



